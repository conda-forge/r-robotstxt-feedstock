{% set version = '0.7.13' %}
{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-robotstxt
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/robotstxt_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/robotstxt/robotstxt_{{ version }}.tar.gz
  sha256: 872a37a548f1cdaf13ca6d01d45498431c601c157fbc1aa412acbce32053baf4

build:
  merge_build_host: True  # [win]
  number: 0
  noarch: generic
  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - {{ posix }}zip               # [win]
    - cross-r-base {{ r_base }}    # [build_platform != target_platform]
  host:
    - r-base
    - r-future >=1.6.2
    - r-future.apply >=1.0.0
    - r-httr >=1.0.0
    - r-magrittr
    - r-spiderbar >=0.2.0
    - r-stringr >=1.0.0
  run:
    - r-base
    - r-future >=1.6.2
    - r-future.apply >=1.0.0
    - r-httr >=1.0.0
    - r-magrittr
    - r-spiderbar >=0.2.0
    - r-stringr >=1.0.0

test:
  commands:
    - $R -e "library('robotstxt')"           # [not win]
    - "\"%R%\" -e \"library('robotstxt')\""  # [win]

about:
  home: https://docs.ropensci.org/robotstxt/, https://github.com/ropensci/robotstxt
  license: MIT
  summary: Provides functions to download and parse 'robots.txt' files. Ultimately the package
    makes it easy to check if bots (spiders, crawler, scrapers, ...) are allowed to
    access specific resources on a domain.
  license_family: MIT
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/MIT'
    - LICENSE

extra:
  recipe-maintainers:
    - conda-forge/r
